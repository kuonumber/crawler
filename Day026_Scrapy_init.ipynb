{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day026_Scrapy_init.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/yP9SVOYorjiFRSG3UDj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuonumber/crawler/blob/master/Day026_Scrapy_init.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru7BFAo-ImFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CxAAh_uLusW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxHykIVZJFKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_file_url = 'https://pycrawler-fileentity.cupoy.com/marathon/homework/data/1586231259497/Day026_Scrapy_init.zip?t=1586231267841'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFXiBzgEJt7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "cf059335-2ca8-42a7-c04d-54f00be00ed4"
      },
      "source": [
        "! wget $zip_file_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-17 01:20:12--  https://pycrawler-fileentity.cupoy.com/marathon/homework/data/1586231259497/Day026_Scrapy_init.zip?t=1586231267841\n",
            "Resolving pycrawler-fileentity.cupoy.com (pycrawler-fileentity.cupoy.com)... 13.224.2.119, 13.224.2.104, 13.224.2.118, ...\n",
            "Connecting to pycrawler-fileentity.cupoy.com (pycrawler-fileentity.cupoy.com)|13.224.2.119|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22310 (22K) [application/octet-stream]\n",
            "Saving to: ‘Day026_Scrapy_init.zip?t=1586231267841’\n",
            "\n",
            "Day026_Scrapy_init. 100%[===================>]  21.79K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2020-09-17 01:20:12 (7.58 MB/s) - ‘Day026_Scrapy_init.zip?t=1586231267841’ saved [22310/22310]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B52Igz1PJuA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4bf828-4602-4f87-c6b7-5c850369a155"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Day026_Scrapy_init.zip?t=1586231267841'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugZzNSvOKBUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8da12c29-e1a9-402a-9b9f-9458aad8b99a"
      },
      "source": [
        "zipfile.is_zipfile('./Day026_Scrapy_init.zip?t=1586231267841')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd8mak84KWVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip = zipfile.ZipFile('Day026_Scrapy_init.zip?t=1586231267841')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79mzlqB5Ki_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip.namelist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CWb2AH1I6pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-imEqNZpKyT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6074b55-06a7-430b-af23-b60cad01c8d5"
      },
      "source": [
        "!ls Day026_Scrapy_init/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "myproject  Pipfile  Pipfile.lock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnQGXi1QMtk2",
        "colab_type": "text"
      },
      "source": [
        "# my own code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnZFeevahjFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install Scrapy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EisJgDZ1qCqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1ivIl-LqCnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://www.inside.com.tw/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1GpAgbvqChf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = requests.get(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX6yN6VZqCY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(res.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8JCcZPHqfBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b09bc3c-f4e7-4fe0-aa86-c8aa931be141"
      },
      "source": [
        "soup.select('.js-auto_break_title')[0]['href']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://www.inside.com.tw/article/20956-2020-apple-event-watch-6-SE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-ltgrJYdAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[u['href'] for u in soup.select('.js-auto_break_title')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_RHCJpKaTVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = requests.get([u['href'] for u in soup.select('.js-auto_break_title')][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R-ONDfSaTZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(res.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTnk1PwMaUOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eb3737fd-79ff-4451-cf28-8d9737b0bc26"
      },
      "source": [
        "soup.select('.post_header_title')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<h1 class=\"post_header_title js-auto_break_title\">蘋果發表會 Apple Watch Series 6、Watch SE 與 Apple One 登場</h1>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXQWy_Lf0ahO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "d2669abf-3763-451d-b4db-e56b2b1e3c8d"
      },
      "source": [
        "[pp.text for line in soup.select('#article_content') for pp in line.select('p')]\n",
        "# .select('p')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['蘋果秋季發表會於今日美國加州時間上午十點，台灣時間凌晨一點登場，一如往常地由蘋果大家長-執行長庫克（Tim Cook）於 Apple Park 為年度的盛會揭開序幕，名為「Time Flies」的主題，時光飛逝自疫情爆發以來度過半年的時間，今年疫情影響數位科技與網路更是更顯重要，像是遠距工作、遠距學習大需求，庫克以破題法告訴大家今天聚焦在 Apple Watch 以及 iPad。',\n",
              " '過去在 Apple Watch 上救命的案例不少，也幫助高血壓患者、視障者等在生活上更便利，而因應疫情，在今年市場更加關注醫療話題，本次也聚焦在健康功能。',\n",
              " '首先，如預期的推出 Apple Watch Series 6，除了藉由 watchOS 7 實現睡眠追蹤，也新增傳說中的血氧功能，可透過動作和心率測量最大攝氧量的數值區間，這是過去專業診所上提供的功能，如今搭配 watchOS 7 也能實現進行預測，並在數值異常時發出提醒。',\n",
              " '在外觀部分，藍色金屬表面、金色不鏽鋼外觀、還有石墨色的黑灰不鏽鋼金屬錶殼，更首次帶來紅色的錶殼，同時也推出一款新的單圈錶帶，彈性、防水更簡約，還有編織的錶帶、新色 Nike 錶帶。另外，與藝術家合作推出更多錶面，也能使用自己的 memoji 更加趣味。',\n",
              " '根據介紹，透過感應器計算用戶血液顏色得出血液的含氧量，15 秒完成一次測量。同時在後台上會定期產出量測報告並儲存在健康 App 上，在今年疫情之際，血氧和動脈測氧器經常被提起，血氧飽和度能知道目前氧氣輸送的情形，和整體的心肺健康，而現在也能利用血氧 App 助力於相關的醫學研究上，Apple 已於許多醫療專家與機構合作。',\n",
              " '採用第六代晶片 S6，雙核處理器由基於 iPhone 11 的 A13 打造，並根據 Apple Watch 需求做優化，與前代相比，速度快了 20%，也強調 Watch 使用 100% 循環利用的材質打造，Apple Watch Series 6 GPS 版售價 399 \\xa0美元。',\n",
              " '另外，在戶外更多人性化的功能，比如戶外亮度自動增加 2.5倍，可以監測海拔高度。當然也可以充分利用 Watch \\xa0上的 App 實現更多功能，像是追蹤太陽位置。',\n",
              " '再來是家長安心孩子更小心的家人共享功能，新增「家庭配對」（Family Setup）即便孩子、年邁長輩沒有手機，仍然可以啟動定位通知，遠端監控勿擾模式、限制互動，了解孩子的學習狀態，設置需要 Apple Watch 4 以上 LTE 版本，支援十二個國家電信商，台灣中華電信也出現在發表會的投影片中。',\n",
              " '接著，如預期中推出平價版的 Apple Watch SE ，結合 Apple Watch Series 6 設計，包含健身等核心功能的平價版智慧手錶，基本的加速感應器、陀螺儀、指南針與高度計都包含，也有最新的運動感應器，因此也支援跌倒監測，而 Watch SE 採用 S5 晶片，運作效能比 Series 3 快兩倍，售價 279 美元起，支援分期付款每月 12 \\xa0美元。',\n",
              " 'Apple Watch Series 6 台幣 12900 元起與 Apple Watch SE 台幣 8900 元起，9/17 開放預購，9/23 開始陸續出貨。',\n",
              " '另外，蘋果推出健身訂閱服務 Fitness+，更便利在運動訓練上，能在大螢幕上顯示當下運動數據，有 10 種不同的鍛煉類型，包含騎自行車、跑步機、瑜伽、核心訓練、划船等。如果速度太快或太慢，Apple Watch 也會提醒，並提供更精確的心率、每分鐘步數等運動數值，Fitness＋ 將在澳洲、加拿大、愛爾蘭、紐西蘭、英國和美國年底前上市，每月 9.99 美元，一年訂閱優惠 79 .99 美元。',\n",
              " '接著也一同宣布傳聞中的訂閱套餐服務，全新的訂閱服務「Apple One」，讓用戶可以一次訂購多種 Apple 軟體服務，包含 Apple Music、TV+、Arcade、Fitness+，三種方案包含個人、家庭與進階版，分別是14.95 \\xa0美元、19.95 \\xa0美元、29.95 \\xa0美元。',\n",
              " '根據 Apple 說法，目前標準每月定價，個人方案每月可節省超過 6 美元，而家庭計劃每月可節省 8 美元。Premier 計劃每月可節省超過 25 美元。',\n",
              " '3:18 更新 Apple One 方案台灣售價：',\n",
              " '核稿編輯：李柏鋒',\n",
              " '延伸閱讀：',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLimWAIy0apS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNzm0EUEaUSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb0cc823-f7b8-41c8-c788-60adfa34a0d3"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk4eOV7tii3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "883618c2-cbf9-4be9-dca6-29787777e18f"
      },
      "source": [
        "!scrapy startproject myproject_inside"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: scrapy.cfg already exists in /content/myproject_inside\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZURdMYlOi5IP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "466a31d6-9b8f-41cb-a5c7-96888a5089a3"
      },
      "source": [
        "!scrapy genspider InsideCrawler inside.com.tw\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created spider 'InsideCrawler' using template 'basic' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66amVMI0kJSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from PTTCrawler import PttcrawlerSpider"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTEoU7Lnktqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PttcrawlerSpider.start_requests(self)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCidItvuqfJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a15556e9-1c69-49f8-b684-47a157609a73"
      },
      "source": [
        "# !scrapy crawl InsideCrawler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scrapy 2.3.0 - no active project\n",
            "\n",
            "Unknown command: crawl\n",
            "\n",
            "Use \"scrapy\" to see available commands\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkKvKBelbO6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!scrapy runspider InsideCrawler.py -s USER_AGENT='Mozilla/5.0'\n",
        "\n",
        "''' 403 代表有防爬蟲，\n",
        "1. 可以再command line 加入-s參數 \n",
        "2. 可以加入此段程式碼\n",
        "def start_requests(self):\n",
        "    yield scrapy.Request('https://www.inside.com.tw/',\n",
        "          headers={'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\"})\n",
        "3. 調整 setting 中的 user-agent 項目    \n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0VdBTUL411w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f29b50a6-3991-468e-a100-9ec8db369c5f"
      },
      "source": [
        "!scrapy runspider InsideCrawler.py -s USER_AGENT='Mozilla/5.0' \n",
        "# -o inside.json -t json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-17 09:51:39 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: scrapybot)\n",
            "2020-09-17 09:51:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Jul 17 2020, 12:50:27) - [GCC 8.4.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 3.1, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2020-09-17 09:51:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2020-09-17 09:51:39 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True, 'USER_AGENT': 'Mozilla/5.0'}\n",
            "2020-09-17 09:51:39 [scrapy.extensions.telnet] INFO: Telnet Password: e6152d710a4ff2b4\n",
            "2020-09-17 09:51:39 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2020-09-17 09:51:39 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2020-09-17 09:51:39 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2020-09-17 09:51:39 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2020-09-17 09:51:39 [scrapy.core.engine] INFO: Spider opened\n",
            "2020-09-17 09:51:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2020-09-17 09:51:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2020-09-17 09:51:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.inside.com.tw/> (referer: None)\n",
            "2020-09-17 09:51:39 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://www.inside.com.tw?page=2> (referer: https://www.inside.com.tw/)\n",
            "2020-09-17 09:51:39 [scrapy.core.engine] DEBUG: Crawled (400) <GET https://www.inside.com.tw?page=3> (referer: https://www.inside.com.tw/)\n",
            "2020-09-17 09:51:39 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2020-09-17 09:51:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 1933,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 19666,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'downloader/response_status_count/400': 2,\n",
            " 'elapsed_time_seconds': 0.556291,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2020, 9, 17, 9, 51, 39, 983850),\n",
            " 'log_count/DEBUG': 3,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 144805888,\n",
            " 'memusage/startup': 144805888,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 3,\n",
            " 'scheduler/dequeued': 3,\n",
            " 'scheduler/dequeued/memory': 3,\n",
            " 'scheduler/enqueued': 3,\n",
            " 'scheduler/enqueued/memory': 3,\n",
            " 'start_time': datetime.datetime(2020, 9, 17, 9, 51, 39, 427559)}\n",
            "2020-09-17 09:51:39 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpjRypZ05RNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/content/InsideCrawler.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydKsSeE8tOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# !scrapy runspider InsideCrawler.py \n",
        "\n",
        "# Following hyperlink and “Filtered offsite request” - https://stackoverflow.com/questions/17862474/following-hyperlink-and-filtered-offsite-request\n",
        "# allowed_domains , 不應該包含\"http://www\", \"https://www\" 和 結尾有 \"/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-LjePF1cjVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !scrapy runspider InsideCrawler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ttJvPh6sS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "6d45f748-e74d-4302-c9cb-670648e56cd4"
      },
      "source": [
        "%cat InsideCrawler.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import scrapy\n",
            "from bs4 import BeautifulSoup\n",
            "from myproject_inside.myproject_inside.items import MyprojectInsideItem\n",
            "from scrapy.spiders import CrawlSpider, Rule\n",
            "from scrapy.linkextractors import  LinkExtractor\n",
            "\n",
            "class InsidecrawlerSpider(CrawlSpider):\n",
            "\n",
            "# class InsidecrawlerSpider(scrapy.Spider):\n",
            "    name = 'InsideCrawler'\n",
            "    allowed_domains = ['inside.com.tw']\n",
            "    start_urls = ['http://www.inside.com.tw/']\n",
            "    rules = [\n",
            "        Rule(LinkExtractor(allow=('/?page=[1-3]$')),\n",
            "         callback='parse_list', follow=True)\n",
            "    ]\n",
            "\n",
            "    def parse_list(self, response):\n",
            "        soup = BeautifulSoup(response.body, 'lxml')\n",
            "        for t in soup.select('.js-auto_break_title'):\n",
            "            # print(t.text)\n",
            "            yield scrapy.Request(t['href'], self.parse_detail)\n",
            "            \n",
            "    def start_requests(self):\n",
            "        yield scrapy.Request('https://www.inside.com.tw/',\n",
            "                      headers={'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36\"})\n",
            "    \n",
            "    def parse_detail(self, response):\n",
            "        print(\"SCRAP EVERY LINK\")\n",
            "        soup = BeautifulSoup(response.body, 'lxml')\n",
            "        print(soup.select('.post_header_title')[0].text)\n",
            "        inside_item = MyprojectInsideItem()\n",
            "        inside_item['title'] = soup.select('.post_header_title')[0].text\n",
            "        inside_item['content'] =  [pp.text for line in soup.select('#article_content') for pp in line.select('p')]\n",
            "        return inside_item\n",
            "        # print(soup)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B8HLDlf-HEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8006719c-a3d5-4ae4-b0ce-497c62900c97"
      },
      "source": [
        "%cat /content/myproject_inside/myproject_inside/items.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Define here the models for your scraped items\n",
            "#\n",
            "# See documentation in:\n",
            "# https://docs.scrapy.org/en/latest/topics/items.html\n",
            "\n",
            "import scrapy\n",
            "\n",
            "\n",
            "class MyprojectInsideItem(scrapy.Item):\n",
            "    # define the fields for your item here like:\n",
            "    title = scrapy.Field()\n",
            "    content = scrapy.Field()\n",
            "    # time = scrapy.Field()\n",
            "    # pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE3XJu1B_vnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scrapy.spiders import CrawlSpider, Rule\n",
        "from scrapy.linkextractors import  LinkExtractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koxs472jdk5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Rule(  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRjh2-fFYObK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LinkExtractor(allow=('https://www.inside.com.tw/?page=[1-3]$'), callback=parse_list, follow=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}